{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e55024f6-48aa-46ae-ae28-c8e342b41d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import TFDistilBertForSequenceClassification\n",
    "from transformers import set_seed\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81a58130-e8c9-4e5a-8080-8e0a90e98171",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "val_df = pd.read_csv(\"../data/validation.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56356a8e-bc73-432d-902e-70f7c6125df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ba9fa14-53a1-44c4-9d13-1baed5ba3c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentences, max_length=100, padding='max_length'):\n",
    "    return tokenizer(\n",
    "        sentences,\n",
    "        truncation=True,\n",
    "        padding=padding,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"tf\" \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac239be7-6e4d-4ceb-854d-2031c1c9db7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_x_train = train_df[\"Comment_Adj\"].tolist()\n",
    "bert_y_train = train_df[\"Result_Bin\"].tolist()\n",
    "bert_x_val = val_df[\"Comment_Adj\"].tolist()\n",
    "bert_y_val = val_df[\"Result_Bin\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c468de7-c416-4ec6-8a86-0984f0671c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenize(bert_x_train)\n",
    "val_encodings = tokenize(bert_x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4ace8c8-91e6-4a5d-bc5e-2a2dccfebcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.convert_to_tensor(bert_y_train, dtype=tf.int32)\n",
    "val_labels = tf.convert_to_tensor(bert_y_val, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "783c1b81-4d0b-40bb-9c05-3faa24a9c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),  \n",
    "    train_labels\n",
    ")).shuffle(1000).batch(50).prefetch(1)\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),  \n",
    "    val_labels\n",
    ")).batch(50).prefetch(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d46d7bd2-808e-415b-878b-5e0146cb2705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "seed_value = 42\n",
    "set_seed(seed_value)\n",
    "\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased',num_labels=2)\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=5e-5)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "\n",
    "model.fit(\n",
    "    x=train_dataset,\n",
    "    y=None,\n",
    "    validation_data=validation_dataset,\n",
    "    batch_size=50,\n",
    "    epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27efb0a6-3c0f-4008-b73c-b6e8be59e473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce5347-1fbb-4221-bba1-755dca9fb02d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd32adf7-f9ce-4f69-906d-512605241679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8de98b-5d6a-44e7-b2c0-df3bea554231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (testenv)",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
